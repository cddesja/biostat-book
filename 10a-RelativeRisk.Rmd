Comparing proportions is of interest for studies in which the outcome is categorical and there are two or more groups. We will focus on the simplest situation where the outcome is binary (e.g., dead/alive, disease progressed/did not progress) and two groups are being compared (e.g., exposed/not exposed, treatment/control). 

This lecture focuses on comparing proportions from prospective studies: 
cohort studies, in which the two groups of interest are typically those exposed and those not exposed to some risk factor, or 
clinical trials, in which the two groups of interest are participants who received a new treatment and participants who served as controls. 
Have you heard the saying: an aspirin a day keeps heart attacks away? A key study that helped to support this claim was the Physicians Health Study1, which was a double-blind, placebo-controlled, randomized trial that began in the 1980’s. 

The researchers in this study recruited male physicians in the US aged 40-84 years old. Of those who were contacted, 22,071 physicians volunteered and were eligible to participate. The men were randomly assigned to one of two groups–daily low-dose aspirin pill group or daily placebo pill group–and were monitored for cardiovascular endpoints. In particular, the primary outcome of interest for this study was first heart attack. 

After five years, 139 of the 11,037 men in the aspirin group had had a heart attack while 239 of the 11,034 men in the placebo group had had a heart attack. Translating these values into a proportion, 0.013 of the men in the aspirin group and 0.022 in the placebo group had had a heart attack.

Based on this, we can see that the proportion of heart attacks is higher in the placebo group than the aspirin group. How might we obtain a single quantity to compare these two groups? And, could this large of a difference be the result of sampling variability or is this evidence of a difference? Let’s use statistical methods to answer these questions.

References: 
1Steering Committee of the Physicians' Health Study Research Group*. "Final report on the aspirin component of the ongoing Physicians' Health Study." New England Journal of Medicine, 321.3 (1989): 129-135.*Note: There was a typo in the transcript. While the transcript has been updated for Spring 2021 (bold and underlined text is the updated information), the audio recording still has the error. This will get corrected once we return back to working in the office.

When we have two binary categorical variables, we can display the counts for each combination of categories in a two by two (2x2) contingency table. The recommended way to display the 2x2 table is to have the two groups that are being compared in the rows and the outcome of interest in the columns, with the ”event” of interest in the first column. The sample size for group 1 and group 2 are denoted as n1 and n2 in the table (the last column in the table) and these would add up to the total sample size, n, for the entire study. We denote the counts in the middle of the table as
a for those in group 1 who had the event of interest; 
b for those in group 1 who did not have the event of interest;
c for those in group 2 who had the event of interest; and, 
d for those in group 2 who did not have the event of interest.
It is very important to set your table up with the rows and columns in the order presented on this slide. If you mix up the rows and columns, then you are mixing up a, b, c, and d and the formulas as presented in this lecture won’t be correct. 

One summary measure of interest might be calculating the proportion who had the event in each of the groups. The proportion who had the event in group 1 is a divided by the total in group 1, n1. Similarly for group 2: the proportion who had the event in group 2 is c divided by the total in group 2, n2. Because these proportions are from a sample, we label them p-hat1 and p-hat2, and they are point estimates of the population proportions, p1 and p2. This type of proportion is called a conditional proportion (or a conditional probability), because we are focusing our attention on only one row (or sometimes one column) in the table and finding the proportion with the event for those within that row. In technical terms, we are looking at the proportion of something, conditional on being in a particular group. In notation, we denote this as Pr[U | V], which can be read as the probability that U will occur given V. To make it more concrete, p-hat1 could also be written as Pr[Event | Group 1], or the probability of having the event given you are in group 1. 

There is another term for these proportions: risk. The estimated risk of having an event is another name for the proportion with the event in a prospective study. The “risk” terminology can only be used in prospective studies (cohort studies or clinical trials) in which participants are followed over time, since it expresses the number who experienced the outcome as a proportion of all those who were at risk at the start of the study. 

In epidemiologic usage, a person is “at risk” of an outcome if 1) they are capable of having it, and 2) they haven’t had it yet. A person is at risk of lung cancer if they have a lung and don’t have lung cancer already. A person is at risk of death if they are alive. Note that this usage of the phrase “at risk” differs substantially from the colloquial usage you are likely to see in newspapers or public policy reports. Once we have the risk estimates for each group, how might we create a single quantity to compare the risks in the two groups? Popular comparative measures are differences (subtraction) and ratios (division). The former is used to make absolute comparisons (e.g., 10% higher) and the latter is used to make relative comparisons (e.g., 2 times more). 

When comparing proportions (or risks) using subtraction, the difference between two proportions (or risks) is called a risk difference (RD). It is also sometimes called the “attributable risk”. The risk difference is defined as the value of the risk of the event in group 1 (p-hat1) minus the risk of the event in the group 2 (p-hat2). In most cases, group 1 is the group of interest and group 2 is the reference or control group. 

If the group of interest has the higher risk, then the risk difference will be a positive value, whereas if the group of interest has the lower risk, then the risk difference will be a negative value.If we compared proportions (or risks) using division, the ratio between two proportions (or risks) is called a relative risk (RR). The relative risk is defined as the risk of the event in group 1 (p-hat1) divided by the risk of the event in group 2 (p-hat2). Similar to risk difference, group 1 is the group of interest and group 2 is the reference or control group. 

If the group of interest has the higher risk, then the relative risk will be a value greater than 1, whereas if the group of interest has the lower risk, then the relative risk will be a value less than 1.

An alternative way of interpreting this ratio is to translate this value into a percent. If the relative risk is less than 1, we translate this into a % decrease (since the risk is less in the group of interest than in the reference group). We do this by taking (1-RR)*100. If the relative risk is greater than 1, we translate this into a % increase (since the risk is more in the group of interest than in the reference group). We do this by taking (RR-1)*100. The data from the Physicians Health Study are shown here again. The risks of heart attack for both groups were presented in an earlier slide, but now the complete details of the calculations are shown here. The risk of having a heart attack for those in the aspirin group was 139 divided by 11,037, which equals 0.013. The risk of having a heart attack for those in the placebo group was 239 divided by 11,034, which equals 0.022. 

The risk difference for this example is 0.013 minus 0.022, which is -0.009. This means that the absolute risk of having a heart attack is 0.009 lower in the aspirin group as compared to the placebo group. 

The relative risk is 0.013 divided by 0.022, which is 0.581. This means those who took aspirin had 0.581 times the risk of having a heart attack compared to those who took the placebo. 

An alternative interpretation of the RR is that, since the RR was less than 1 in the Physicians Health Study, we would calculate the percent reduction in risk as (1-0.581)*100 = 41.9%. This means that those who took aspirin had a 41.9% reduction in risk of heart attack compared to those who took placebo.

We know that if we repeated this study, the estimated risk values in each group would be slightly different, due to sampling variability. Let’s use statistical inference (specifically, interval estimation) on these summary measures to understand if what we observed is due to sampling variability or if there is evidence of a real difference. The other inferential method, hypothesis testing, for comparing proportions will be presented in a future lecture.Recall that the general formula for a confidence interval is the point estimate plus or minus the margin of error. Filling in these details for estimating a difference of two population proportions (or risks):

--The point estimate is the difference between the two sample proportions (or risks), that is, the risk difference. 

--The confidence interval is the point estimate plus or minus the degree of confidence, which is the appropriate z-value, times the estimated standard error for the difference in the sample proportions (or risks). 

--The estimated standard error for this situation looks similar to the SE value described in a previous lecture on confidence intervals for a proportion but now applies to a two-group situation: the square root of the sample proportion in group 1 (p-hat1) times 1 minus the sample proportion in group 1, all over the sample size for group 1 (n1), plus, the sample proportion in group 2 (p-hat2) times 1 minus the sample proportion in group 2, all over the sample size for group 2 (n2). 

The confidence interval formula presented on this slide only applies when all of the assumptions are met for comparing two proportions. (These assumptions will be presented in a upcoming slide.) Remember to check the assumptions first before carrying out any inferential method.  Recall that the values in a confidence interval provide plausible values for the true population parameter, but we can also use it to make conclusions about statistical significance. How might we do this for risk difference? When using comparison measures, it’s good to ask yourself, “If the two groups were equal (the null hypothesis were true), what value would result using this comparison measure (the null value)?”. In the case of a risk difference, if the two groups were equal and we took the difference between them, then the (null) value would be 0. 

Using similar logic to what was presented in a previous lecture, if the null value does not fall within the confidence interval limits, then this value is not plausible and therefore, we would have evidence that the true population value is different than the null value. That is, the results are statistically significant and there is evidence of a difference in proportions between the two groups. This situation is shown in the first plot above: the confidence interval does not include the null value of (in this case) zero. 

Conversely, if the null value falls within the confidence interval limits, then it is a plausible value (one of many different plausible values), and we would not have enough evidence to say the true population value is different than the null value. That is, the results are not statistically significant and there is not enough evidence of a difference in proportions between the two groups. This situation is shown in the second plot above: the confidence interval DOES include the null value of zero. Now let’s calculate the confidence interval for the risk difference for the Physicians Health Study example. 

The sample risk difference of having a heart attack between the aspirin and control groups is -0.009 and the estimated standard error for the difference is 0.002. The z-value for a 95% confidence interval is the value in the Standard Normal distribution with 0.975 area lying below that value, so the z-value is 1.96. Putting all of those values together–the point estimate, the z-value, and the standard error–a 95% confidence interval for the difference in the population risk of having a heart attack between the aspirin and control groups is between -0.011 and -0.007.

We are 95% confident that the difference in risk of heart attack between the aspirin and control groups is between -0.011 and -0.007. Or we could say, a range of plausible values for the true difference in risk of heart attack between the aspirin and control groups is from -0.011 to -0.007. Because the 95% confidence interval does not include 0, then zero is not a plausible value and we can conclude that the difference in risk of heart attack between the aspirin and control groups is statistically significant. There is evidence of a difference in risk of heart attack between the two groups, with aspirin having between 0.007 to 0.011 (or 0.7% to 1.1%) lower risk than the placebo group. Unlike the usual calculation for a confidence interval as presented for risk difference, computing a confidence interval for relative risk is a two-step procedure. 

We see that the first step looks very similar to the general formula for a confidence interval: point estimate plus or minus the margin of error. But it is for the natural log of the relative risk. This is because the sampling distribution for relative risk does not follow a normal distribution, no matter what the sample size is. But, if we take the natural log of the sample relative risk, then the sampling distribution for this transformed measure is approximately normal. Applying this transformation allows us to use normal-based methods for calculating the confidence interval. 

So, Step 1 is to calculate the CI for the natural log of the relative risk, where: 

--The point estimate is the natural log of the sample relative risk. 

--The degree of confidence is the appropriate z-value, and 

--The estimated standard error of the natural log of relative risk is as shown on the slide. 

Then, Step 2 is to back transform the confidence interval values found for the natural log of RR by taking the antilog: the exponential function. This will produce the lower and upper limits of the confidence interval for relative risk (on the original scale). 

The confidence interval formula presented on this slide only applies when all of the assumptions are met for comparing two proportions. (These assumptions will be presented in a upcoming slide.) Remember to check the assumptions first before carrying out any inferential method.  Similar to the approach used for risk difference, let’s figure out how we can make conclusions about statistical significance using relative risk. Let’s ask the same question again: “If the two groups were equal (the null hypothesis were true), what value would result using this comparison measure (the null value)?”. If the two groups were equal and we took the ratio between them, then the (null) value would be 1. 

So if the null value does not fall within the confidence interval limits, then this value is not plausible and therefore, we would have evidence that the true population value is different than the null value. This situation is shown in the first plot above: the confidence interval does not include the null value of (in this case) one. 

Conversely, if the null value falls within the confidence interval limits, then it is a plausible value (one of many different plausible values), and we would not have enough evidence to say the true population value is different than the null value. This situation is shown in the second plot above: the confidence interval DOES include the null value of one. 
Now let’s calculate the confidence interval for the relative risk for the Physicians Health Study example. 

The sample relative risk of having a heart attack between the aspirin and control groups is 0.581. Taking the natural log of this value gives us -0.542, and the estimated standard error for the natural log of RR is 0.106. The z-value for a 95% confidence interval is the value in the Standard Normal distribution with 0.975 area lying below that value, so the z-value is 1.96. Putting all of those values together–the point estimate, the z-value, and the standard error–a 95% confidence interval for the ln(RR) is between -0.750 and -0.335. Now we need to exponentiate those limits to get the 95% CI for the relative risk: e^(-0.750) equals 0.473 and e^(-0.335) = 0.715. 

We are 95% confident that the relative risk of heart attack between the aspirin and control groups is between 0.473 and 0.715. Or we could say, a range of plausible values for the true relative risk of heart attack between the aspirin and control groups is from 0.473 to 0.715. Because the 95% confidence interval does not include 1, then one is not a plausible value and we can conclude that the relative risk of heart attack between the aspirin and control groups is statistically significant. There is evidence of a difference in risk of heart attack between the two groups, with aspirin having between 0.473 to 0.715 times the risk of the placebo group (or 28.5% to 52.7% reduction in risk).Statistical inference (e.g., interval estimation) for comparing risks relies on several assumptions. 

The samples should be random (or representative) samples from the respective populations, to allow us to generalize the results to those populations; 

The observations within each group should be independent of one another and the observations in one group should be independent of the observations in the other groups. 

We assume that the sample is “large enough” for the sampling distribution of risk difference or the sampling distribution for the natural log of the relative risk to be approximately Normal. For these statistics, “large enough” requires the counts in the middle of the 2x2 table (a, b, c, and d) to be at least 5. In our example, this assumption would be met if our sample contained at least 5 people in each of the cells in the table. If the sample size is too small, consider using other methods, such as the correction methods, to compute confidence intervals.

If these assumptions are violated, the confidence intervals we calculate may give us faulty information about the true population proportion. Both the risk difference and the relative risk summarize the 2x2 table data using a single number. However, neither the RD nor the RR gives a complete picture of the impact of an exposure or proposed treatment. 

Reporting only the relative risk can be misleading. Reducing the risk of disease by 50% sounds impressive, but if the disease is rare, then such a reduction may have little practical impact. To see why, consider the following situation. Suppose we have developed a vaccine that halves the risk of a particular disease, so the risk of the disease in the vaccinated is half that in the unvaccinated (RR = 0.50). What impact will our new vaccine have? (Refer to the left side of the slide above.)
In Case 1, the disease is quite rare; the risk of disease in the unvaccinated is only 2 in 10 million. Our new vaccine cuts the risk in half, so the risk of disease in the vaccinated is 1 in 10 million. The risk difference, therefore, is 1 in 10 million. 
In Case 2, the disease is more common; the risk of disease in the unvaccinated is 20%. Our new vaccine cuts the risk in half, so the risk of disease in the vaccinated is 10%. The risk difference, therefore is 10%. 
Our new vaccine would have much more impact in Case 2, where the prevalence of the disease is high, than in Case 1, where the disease is rare, even though the relative risk is the same. 

On the other hand, reporting only the risk difference can also be misleading. Let’s consider an environmental contaminant, where the exposed people have 1% higher risk than the unexposed people. (Refer to the right side of the slide above.)
In Case 1, the risk of the disease in unexposed people is fairly low at 1%, so the contaminant raises the risk to 2%. The contaminant doubles the number of people who can be expected to acquire the disease. The relative risk, therefore, is 2.0.
In Case 2, the risk of the disease in unexposed people is already quite high at 89% (think common cold), so the contaminant raises the risk to 90%. The contaminant increases by only 1% the number of people who can be expected to acquire the disease, so the relative risk is 1.01. 
The contaminant in Case 1 is likely to raise more concern, since it doubles the risk, even though the absolute number of people harmed is the same in both cases. 

It is important to keep the difference between the risk difference and the relative risk in mind when reading the news and medical literature. Researchers have a tendency to report their results in whichever way makes them sound more impressive, for example, reporting benefits with BIG numbers (e.g., relative risk) and harms with small numbers (e.g., risk difference). This is misleading. A famous researcher who studies how people understand risk, Gerd Gigerenzer1, suggests that researchers report absolute measures over relative measures because it’s easier to understand them. The key point is that the impact of an exposure or treatment depends on how common the condition or disease is in the first place.

References: 
1“Helping doctors and patients make sense of health statistics: towards an evidence-based society”, a keynote presentation at the 8th International Conference on Teaching Statistics (ICOTS) in Ljubljana, Slovenia, July 11-16, 2010