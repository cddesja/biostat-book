This lecture focuses on comparing proportions from case-control studies, in which the two groups of interest are cases (people who have the disease of interest) and controls (people who do not have the disease). Recall that case-control studies are carried out after the fact (or retrospectively). The researchers purposefully select cases who have already experienced the outcome of interest and then purposefully select controls who have not experienced the outcome. The number of controls is chosen in advance to be an integer multiple of the number of cases, and controls are typically chosen to be similar to the cases in age, gender, and other relevant characteristics. The researchers then look retrospectively back in time to see how many of the cases and how many of the controls were exposed to the risk factor in the past. In contrast, prospective studies select participants who do not have the disease and follow them forward in time to see if the risk of experiencing the outcome depends on group or exposure status. However, prospective studies can be time-consuming and expensive to do, especially if it takes years for the outcome or event of interest to occur, or if the outcome is very rare. Case-control studies are useful for exploring possible risk factors for a disease or condition, and are often the preferred design for studying rare diseases or outcomes. 

Ideally, we want to compare two proportions using the risk difference or relative risk (as we can in prospective studies), but when we have a case-control study, these measures are meaningless due to the case-control sampling strategy (that is, due to the fact that the number of controls is chosen in advance to be an integer multiple of the number of cases). Instead, we use use another measure of comparison called the odds ratio. Let’s explore an example.

A case-control study1 was carried out to investigate the relationship between antidepressant use during pregnancy and Autism Spectrum Disorder (ASD) in the children. Two-hundred and ninety-eight case children with ASD (and their mothers) and 1,507 randomly selected control children (who don’t have ASD, and their mothers) were drawn from a large health care organization in northern California. The researchers chose to have a ratio of about 5 control children per 1 case child. The control children were matched to case children by sex, birth year, and hospital of birth. The researchers retrospectively collected information about maternal use of antidepressants during the year prior to delivery (the exposure of interest). 

Of the children with ASD, 20 of the mothers had used antidepressant drugs during the year prior to delivery (which is 20 out of 298, or 6.7% of the cases). Of the control children, 50 of the mothers had used the drugs (which is 50 out of 1,507, or 3.3% of the controls). 

Based on this, we can see that the proportion of maternal antidepressant use during pregnancy is higher in the cases than in the controls. How might we obtain a single quantity to compare these two groups? And, could this large of a difference be the result of sampling variability or is this evidence of a difference? Let’s use statistical methods to answer these questions.

References: 
1Croen, L. A., Grether, J. K., Yoshida, C. K., Odouli, R., & Hendrick, V. (2011). Antidepressant use during pregnancy and childhood autism spectrum disorders. Archives of general psychiatry, 68(11), 1104-1112.Before we move on to the statistical methods, let’s discuss the arrangement of the table for case-control studies. 

This table looks similar to what you have seen in a previous lecture, but notice that this table does not have a fourth column with totals, as the table for a prospective study would. This is done intentionally to emphasize the fact that case-control studies must be analyzed differently than prospective studies. It is NOT appropriate to say that of the 70 (=20 + 50) children whose mothers used antidepressants during pregnancy, 20 of them (2.8%) developed ASD, for two reasons. First, the study did NOT begin with people who did not have the outcome (ASD) and then follow them over time to see if they experienced the outcome; it started with children who already had ASD. The risk of a healthy child developing ASD therefore cannot be determined from this study. Second, the number of ASD cases relative to the number of children in the study is fixed in advance by the chosen ratio of controls to cases. Risks, risk differences, and relative risks should never be calculated from a case-control study.So, how do we compare two categorical variables when we have a case-control study? Answer: the odds ratio! 

But first, what are odds? In general terms, odds are the probability of having the event (p) divided by the probability of not having the event (1-p). Probabilities always range between 0 and 1 so odds range between 0 and infinity. For example, if a race horse runs 100 races and wins 10 times and loses the other 90 times, the probability of winning is 10/100 = 0.10 or 10%, but the odds of winning are (10/100)/(90/100) = 10/90 = 0.111 or 11%, or 1 win to 9 loses (notice that the total number of races canceled out between the two probabilities and we were left with count for event divided by count for non-event). Or, as another example, if a horse runs 100 races and wins 60 of them, the probability of winning is 60/100 = 60%, but the odds of  winning are 60/40 = 1.5. Notice that when the probability is low, the odds and the probability are more similar. 

Recall that the recommended way to display the 2x2 table is to have the two groups that are being compared in the rows and the outcome of interest in the columns, with the ”event” of interest in the first column. This is mentioned again because it is very important to have rows and columns in the order presented on this slide. If you mix up the rows and columns, then you are mixing up a, b, c, and d and the formulas as presented in this lecture won’t be correct. 

To calculate odds, we find the odds of being exposed in group 1 (“cases”) and the odds of being exposed in group 2 (“controls”). If the proportion who were exposed in group 1 is a divided by a+c (which is the total number of cases), then the odds of being exposed in group 1 is (a/(a + c)) divided by (c/(a+c)), which turns out to be a/c (because the denominators of a+c cancel out). Similarly, the odds of being exposed in group 2 is b/d. To compare the odds between two different groups using division, we use the odds ratio (abbreviated OR). The odds ratio is defined as the odds of being exposed in group 1 (odds1) divided by the odds of being exposed in group 2 (odds2). As previously stated, group 1 is the “cases” and group 2 is the reference or control group. 

If the group of interest has higher odds than the reference group, then the odds ratio will have a value greater than 1, whereas if the group of interest has lower odds, then the odds ratio will have a value less than 1. 

An alternative way of interpreting this ratio is to translate this value into a percent. If the odds ratio is less than 1, we translate this into a % decrease (since the odds is less in the group of interest than in the reference group). We do this by taking (1-OR)*100. If the odds ratio is greater than 1, we translate this into a % increase (since the odds is more in the group of interest than in the reference group). We do this by taking (OR-1)*100. 

Note that odds ratio may be used in prospective and cross-sectional studies, but it must be used in case-control studies.The data from the Autism and Maternal Antidepressant Use study is shown here again. Of the children with ASD, the odds of the mothers having used antidepressant drugs during the year prior to delivery is 20 divided by 278, which equals 0.072. Of the control children, the odds of the mothers having used the drugs is 50 divided by 1457, which equals 0.034. 

The odds ratio, then, is 0.072 divided by 0.034, which is 2.096. This means that children with ASD had roughly 2 times higher odds of the mothers having used antidepressant drugs during the year prior to delivery compared to control children. 

Alternatively, since the OR was greater than 1, we could calculate the percent increase in odds as (2.096-1)*100 = 109.6%. The odds of the mothers having used antidepressant drugs are increased by 110% in children with ASD compared to controls. Thus far in this lecture, we have been talking about the exposure odds ratio, which is the odds of being exposed, comparing cases to controls. Did this feel odd to anyone (no pun intended)? The exposure happened first and then the outcome (“disease” (in general terms) or ASD in our example). It would be great if we could have a summary measure that we interpret as we intuitively want to, that is, the odds of having the outcome (“disease”) comparing the exposed to the unexposed (called the disease odds ratio). We are in luck! Odds ratios have several useful properties that are almost magical. 

Recall that the exposure odds ratio is a over c, all divided by b over d. Doing a little rearranging gets us to a times d, all divided by b times c. Let’s see how to calculate the disease odds ratio.

If we calculate the odds of having the disease for the exposed, we would focus on only the exposed row in the table: those that have the disease (a) divided by those that don’t have the disease (b). Similarly, if we calculate the odds of having the disease for the unexposed, we would take those that have the disease (c) divided by those that don’t have the disease (d). Putting those two ratios together to get the disease odds ratio results in a over b, all divided by c divided by d. Doing a little rearranging, we get a times d, all divided by b times c. This is exactly the same number as the exposure odds ratio. (Magic!)

As previously noted, it isn’t appropriate to calculate the probability of disease in the exposed in a case-control study. The same logic would apply to calculating the odds of disease as we just did for the disease odds ratio. However, since the disease odds ratio is always exactly the same number as the exposure odds ratio, either of them can be used as measures of the strength of association between exposure and disease. You are likely to see both of them in the published literature. Now let’s use statistical inference (specifically, interval estimation) to understand if what we observed is due to sampling variability or if there is evidence of a real difference. The other inferential method, hypothesis testing, for comparing two categorical variables will be presented in a future lecture.

The calculation of a confidence interval for an odds ratio is similar to the calculation of a confidence interval for a relative risk, in that it’s a two-step procedure. 

We see that the first step looks very similar to the general formula for a confidence interval: point estimate plus or minus the margin of error. But it is for the natural log of the odds ratio. This is because the sampling distribution for odds ratio does not follow a Normal distribution, no matter what the sample size is. But, if we take the natural log of the sample odds ratio, then the sampling distribution for this transformed measure is approximately Normal. Applying this transformation allows us to use normal-based methods for calculating the confidence interval. 

So, Step 1 is to calculate the CI for the natural log of odds ratio, where the 

--The point estimate is the natural log of the sample odds ratio. 

--The degree of confidence is the appropriate z-value, and 

--The estimated standard error of the natural log of odds ratio is as shown on the slide. 

Then, Step 2 is to back transform the confidence interval values found for the natural log of OR by taking the antilog: the exponential function. This will produce the lower and upper limits of the confidence interval for odds ratio on the original scale. 

The confidence interval formula presented on this slide only applies when all of the assumptions are met for comparing two odds. (These assumptions will be presented in a upcoming slide.) Remember to check the assumptions first before carrying out any inferential method. Let’s figure out how we can make conclusions about statistical significance using odds ratio. Let’s ask the same question again that we saw in a previous lecture: “If the odds in the two groups were equal (the null hypothesis), what value would result using this comparison measure (the null value)?”. Because the odds ratio is a ratio measure of comparability, similar to the relative risk, if the odds in the two groups were equal and we took the ratio between them, then the (null) value would be 1. 

So if the null value does not fall within the confidence interval limits, then this value is not plausible and therefore, we would have evidence that the true population value is different than the null value. This situation is shown in the first plot above: the confidence interval does not include the null value of (in this case) one. 

Conversely, if the null value falls within the confidence interval limits, then it is a plausible value (one of many different plausible values), and we would not have enough evidence to say the true population value is different than the null value. This situation is shown in the second plot above: the confidence interval DOES include the null value of one. Now let’s calculate the confidence interval for the odds ratio for the Autism and Maternal Antidepressant Use example. 

The sample odds ratio of having ASD between maternal antidepressant use during pregnancy and no use is 2.096. Taking the natural log of this value gives us 0.740, and the estimated standard error for the natural log of OR is 0.273. The z-value for a 95% confidence interval is the value in the Standard Normal distribution with 0.975 area lying below that value, so the z-value is 1.96. Putting all of those values together–the point estimate, the z-value, and the standard error–a 95% confidence interval for the ln(OR) is between 0.206 and 1.274. Now we need to exponentiate those limits to get the 95% CI for the odds ratio: e^(0.206) equals 1.229 and e^(1.274) equals 3.577. 

We are 95% confident that the odds ratio of having ASD between maternal antidepressant use during pregnancy and no use is between 1.229 and 3.577. Another way of stating this is that the odds of having ASD for children whose mothers used antidepressants during pregnancy is between 1.229 and 3.577 times higher than for children whose mothers did not. Or we could say, a range of plausible values for the true odds ratio for ASD between maternal antidepressant use and no use is from 1.229 to 3.577. Because the 95% confidence interval does not include 1, it is not a plausible value and we can conclude that the odds ratio comparing the two groups is statistically significant. There is evidence of a difference in odds of ASD between the two groups, with those who were exposed to antidepressants in-utero having between 1.229 to 3.577 times the odds of the those who were not exposed (or 22.9% to 257.7% increase in odds). Statistical inference (e.g., interval estimation) for comparing odds relies on several assumptions. 

The samples should be random (or representative) samples from the respective populations, to allow us to generalize the results to those populations; 

The observations within each group should be independent of one another and the observations in one group should be independent of the observations in the other groups. 

We assume that the sample is “large enough” for the sampling distribution for the natural log of the odds ratio to be approximately Normal. For this statistic: 
in a prospective cohort or cross-sectional study, “large enough”  requires both n1*(p-hat1)(1-phat1) and n2*(p-hat2)(1-phat2) to be at least 5, where n1 is the number of exposed individuals, p-hat1 is the sample proportion with the outcome among the exposed individuals, n2 is the number of unexposed individuals, and p-hat2 is the sample proportion with the outcome among the unexposed individuals. 
in a case-control study, “large enough” requires both m1*(p-hat1)(1-phat1) and m2*(p-hat2)(1-phat2) to be at least 5, where m1 is the number of cases, p-hat1 is the sample proportion of cases that are exposed, m2 is the number of controls, and p-hat2 is the sample proportion of controls that are exposed. 
If the sample size is too small, consider using other methods, such as the correction methods, to compute confidence intervals.

If these assumptions are violated, the confidence intervals we calculate may give us faulty information about the true population odds ratio. While the odds ratio is distinct from the relative risk, there are times when it is a reasonable estimate of the relative risk. This is another magical property of the odds ratio. 

If the disease being studied is “relatively rare”, then the sum of a and b (the total exposed) would be approximately equal to b because cell a would be a very small number. And a similar argument for the “not exposed” row: the sum of c plus d would be approximately equal to d. Using these approximations in the relative risk calculations results in the odds ratio formula. So, if the disease is “relatively rare”, the odds ratio from a case-control study is a good approximation of the relative risk that would have been obtained from a prospective study. What would we consider “relatively rare”? Answer: A disease with a prevalence below 10%, but the lower the prevalence, the closer the odds ratio will be to the relative risk. When the prevalence is NOT low, however, the odds ratio always overestimates the strength of the association between exposure and disease. 

The fact that you can get a good approximation to the relative risk from the odds ratio is the reason that odds ratios (rather than some other measure) are used to analyze case-control studies. Relative risks are easier to interpret and easier to explain to non-statisticians (or non-gamblers!) than odds ratios, and they directly express what is usually of interest – i.e. how the risk of getting the disease is affected by the treatment or exposure. 