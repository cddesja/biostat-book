Thus far, we have discussed the use of the t-distribution (via t-tests or confidence intervals) to make conclusions about a single population mean or to compare two population means. Recall that an assumption of this method is that the data values are sampled from a population that is approximately normally distributed, or that the sample size is large enough to invoke the Central Limit Theorem. What approaches are available if it isn’t reasonable to assume normality? What if the data are severely skewed, or contain extreme outliers? This lecture will discuss alternatives to the t-distribution when the normality assumption isn’t met. 
There are two options for analyzing data when the normality assumption is not reasonable.

The first option is to transform the severely skewed data to see if the transformed data appears approximately Normal. If this does the trick, we then carry out inferential procedures using the t-distribution on the transformed data. A common transformation is to take the log of the variable. When a t-test is carried out on the log-scale, we are no longer comparing the usual mean values, but rather comparing the geometric means between two groups.

The second option is to use a method that doesn’t require the data to fit a parametric (e.g., Normal) distribution. These types of methods are called nonparametric methods, or sometimes “distribution-free” methods. Two common nonparametric approaches are simulation-based techniques and rank-based tests. 
For simulation-based techniques, we use the data to construct/simulate an approximate sampling distribution of the statistic. These techniques do not require any assumptions about the shape of the population distribution and can be used for any sample statistic. 

Bootstrapping is used to obtain confidence intervals for any statistic, such as a mean, a difference in means, a median, a standard deviation, etc. This procedure involves repeatedly taking samples with replacement from the original sample, calculating some statistic for each sample, and collecting the results in a dotplot or histogram to approximate what the sampling distribution of the sample statistic would look like. If this sounds familiar, it is! In an earlier lecture we discussed repeatedly taking samples from a population, calculating a statistic of interest for each sample, and collecting the results in a dotplot or histogram: this gives the sampling distribution of the sample statistic. The only difference is in where we are drawing the samples from. If we repeatedly sample from the population, we obtain the sampling distribution of the sample statistic, as discussed in earlier lectures. If we instead repeatedly sample from the original sample itself, assuming that the original sample is representative of the population it came from, we obtain an approximate sampling distribution, called a “bootstrap distribution”. From this bootstrap distribution, we can obtain a 95% confidence interval by simply taking the center 95% of the bootstrap statistics. 

Re-randomization testing is used to carry out hypothesis testing for any statistic. We again use the data to create an approximate sampling distribution of the statistic, but this time we are interested in the sort of statistics we would observe if the null hypothesis were true. So we simulate repeated samples in a way that is consistent with the null hypothesis. For example, if we are comparing two groups, we would randomly reshuffle the group labels (such as “treatment” and “control”) on the observations in our study, calculate the group difference statistic (such as the difference in medians) for each re-randomization sample, repeat the reshuffling many times, and collect the differences in a dotplot or histogram. This histogram shows the approximate sampling distribution of the group difference statistic under the null hypothesis and gives us an idea of how much the treatment difference would be expected to vary if the treatment had no effect. We would compare the observed difference from the actual study to this approximate sampling distribution simulated under the null to make a conclusion about whether there is a significant difference due to treatment. If the observed difference was much different (in either direction) from the null distribution, then we would have evidence that there is a difference between the groups.
The other nonparametric approach is rank-based tests. These methods use the rank or order number of the observations rather than the raw value of the observation. A rank-based alternative to the paired t-test is the Wilcoxon test (also known as the Wilcoxon matched-pairs signed-rank test, or the signed-rank test, or even just the sign test). A rank-based alternative to the two-sample t-test is the Mann-Whitney-Wilcoxon test (also known as the Wilcoxon test or the Wilcoxon-Mann-Whitney test, or the Mann-Whitney test, or the rank-sum test or even just the ranks test). We will focus here on the rank-sum test.

The Mann-Whitney or rank-sum test, as described in many textbooks, technically compares the distributions of a continuous variable in two samples, rather than comparing the two group means as the t-test does. The null hypothesis of the Mann-Whitney test is that the two distributions are the same (same shape, same center, same everything), and the alternative hypothesis is that they are different in some way. 

In principle, this test could be used to see if two distributions differ in shape (but have the same center and spread), or to see if they differ in spread (but have the same shape and center). However, for practical purposes, for the kinds of situations that we are likely to encounter in our careers in medicine and public health, the Mann-Whitney test only has high power (high ability to tell the difference between the two groups) when the two distributions are shifted left or right relative to each other. For that reason, the rank-sum test is in practice a test of medians. The null hypothesis for the rank-sum test is that the two distributions have the same median, and the alternative hypothesis is that one distribution has a different median than the other.

The rank-sum test statistic is calculated from the ranks or order number of the combined data instead of from the actual values. If the null hypothesis is true, we expect the sums of the ranks for the two groups to be equal or approximately equal. 
Let’s walk through the steps for the rank-sum test to understand how rank-based tests work. The Tea, Coffee, and the Immune System study will again be used as the context for the test. 

The sample median gamma interferon production in the coffee group is 15.5 and the sample median in the tea group is much larger, at 47. We want to know if this difference in sample medians is sufficiently large to reject the null hypothesis that the medians in the two populations are the same, or whether a difference of this size could be due to random sampling variability.

To conduct the Mann-Whitney rank-sum test, we first order all of the measured values, regardless of group. The lowest value in the Tea, Coffee, and the Immune System dataset is 0, and there are two of them in the coffee group (known as tied observations). Because of this tie, the two values are both given the average rank of 1.5 (instead of ranks 1 and 2). The next lowest value is 3 (in the coffee group), so that value gets rank=3. The next lowest value is 5 (in the tea group), so that value gets rank=4. This is continued until all of the values have been ranked. If there were no difference in interferon gamma production between the tea and coffee groups, the ranks would end up fairly evenly split (for example, rank 1 might be in the coffee group, rank 2 in the tea group, etc.) and the sums of the ranks in each group would be roughly the same. In this example, the sum of the ranks in the coffee group (85) is lower than the sum of the ranks in the tea group (146): more of the low interferon gamma production values are in the coffee group compared to the tea group. If the goal was to have high amounts of production, then the tea group “won”! There are various methods proposed to calculate the Mann-Whitney test statistic, but only one method will be discussed here. The test statistic, which we will call W, is calculated by summing the ranks of the group with the smaller sample size (which we will call Rs) and then subtracting a continuity correction which is related to the sample size, ns, of the smaller group. Once we have this sample statistic, we compare it to the sampling distribution of the rank-sum statistic under the null hypothesis, which is known from statistical theory (but we won’t discuss it here), in order to obtain a p-value. The p-value quantifies the unusualness of the sample statistic if the null hypothesis of equal medians were true. If there are no ties, the exact p-value is found using the Wilcoxon rank-sum statistic distribution (via tables or software). If there are ties, then an approximate p-value is found using a Normal approximation (again, via tables or software). We will not go into details of the p-value calculation for this test in this course.

The evaluation piece of the hypothesis testing framework is to make a conclusion by comparing the p-value to the significance level, as usual. Let’s apply the rank-sum test to the Tea, Coffee, and the Immune System example. 

Since the coffee group had the smaller sample size, we will calculate W for that group. The sum of the ranks for the coffee group was 85 and there were 10 participants in that group. This results in a W-statistic of 85 minus 10 times 10 plus 1, all over 2, which equals 30. 

There were ties in the data set, so an approximate p-value will be calculated (using software). This value turns out to be 0.084, so we would fail to reject the null hypothesis. There isn’t sufficient evidence to conclude that the median interferon gamma production differs between tea and coffee drinkers. 

In this case, the p-value for the rank-sum test (p = 0.084) is close to the p-value from the t-test (p = 0.068), so the two tests agree that the groups don’t differ significantly. Since the two tests are looking at different things (medians vs. means), however, they may not always agree. It is important to decide which test is appropriate to run before seeing the data. It is considered statistically shady to run both tests and choose the p-value that best fits your pre-conceived idea of what the test result should be. There are a few considerations for rank-based tests to keep in mind.  

Rank-based tests do not require us to assume anything about the population distribution, but they do require a few other assumptions: they require a random or representative sample, and they require that the observations are independent of one another. 

You may have noticed that the names of the rank-based tests are not nearly as standardized as the names of (for example) the t-test or the ANOVA F-test (which will be presented in a future lecture). This can be confusing. It is probably more helpful to focus on what the test is being used for than on its name(s). 

Studies that use rank-based tests usually only report p-values and not confidence intervals. This is because some rank-based tests requires additional assumptions in order for the confidence interval to be valid. For example, the rank-sum test to compare two medians can be extended to provide a confidence interval for the difference in medians, but this requires that we assume the distributions have the same shape. This assumption is not needed to interpret the p-value from a rank-sum test. As a result, some statisticians consider this a serious limitation to these types of methods. 

Finally, keep in mind that rank-based tests are not magic. They can be used in situations where parametric tests such as the t-test cannot be used, but they come with a cost: the rank-based test will typically have lower power to detect a difference than the parametric test would have had, particularly for small samples. They have lower power because they are only considering ranks and not the actual data values, which essentially is throwing away information. However, with large samples, these tests are nearly as powerful as the parametric tests when the data really do come from a normally distributed population. 