This lecture focuses on using confidence intervals to compare means from two independent groups (for example to compare treatment versus control groups, or males versus females). Recall that confidence intervals are used to estimate the true population value: in this case, the true difference in means between the two groups. We will use the same example that we used earlier, in the lecture on hypothesis testing for comparing two means: the Tea, Coffee and the Immune System study.  This lecture will also discuss the relationship between hypothesis testing and confidence intervals. 

When our goal is to compare means from two independent groups, we can use hypothesis testing, as described in a previous lecture, or we can use confidence intervals. Confidence intervals are an alternative method for summarizing the evidence provided by the data. In the case of comparing the population means in two groups, the confidence interval of interest is the one that estimates the true difference between the two population means.

Recall that the general formula for a confidence interval is the point estimate plus or minus the margin of error. Filling in these details for estimating a difference of two population means:

--The point estimate is the difference between the two sample means. 

--The confidence interval is the point estimate plus or minus the degree of confidence, which is the appropriate t-value, times the estimated standard error for the difference in the sample means. 

--The estimated standard error for this situation is the same SE value described in the previous lecture on hypothesis testing for comparing two means: the square root of the standard deviation in group one (s1), squared, over the sample size in group 1 (n1) , plus the standard deviation in group 2 (s2), squared, over the sample size in group 2 (n2). 

--The appropriate degrees of freedom for this t-value is also the same as described in the previous lecture on hypothesis testing for comparing two means. If we were using software, we would just let the software calculate the more precise degrees of freedom for the t-value. Without software, we would use the approximate degrees of freedom by using the smaller of n1 – 1 or n2 – 1. 

The confidence interval formula presented on this slide only applies when all of the assumptions are met for comparing two means. (These assumptions were presented in the previous lecture on hypothesis testing for comparing two means.) Remember to check the assumptions first before carrying out any inferential method.  Now let’s calculate the confidence interval for the Tea, Coffee, and the Immune System example. 

The difference in the sample mean interferon gamma production between the tea and coffee groups is 17.1 and the estimated standard error for the difference is 8.291. The t-value for a 95% confidence interval is the value in the t-distribution with nc - 1 = 9 degrees of freedom and 0.975 area lying below that value, so the t-value is 2.262. Putting all of those values together–the point estimate, the t-value, and the standard error–a 95% confidence interval for the difference in the population mean interferon gamma production between the tea and coffee groups is -1.7 to 35.9.

We are 95% confident that the difference in mean production between the tea and coffee groups is between -1.7 and 35.9. Or we could say, a range of plausible values for the true difference in mean production between the tea and coffee groups is from -1.7 to 35.9. 
Now that the two primary procedures for statistical inference – hypothesis testing and estimation via confidence intervals – have been presented for both a single mean and comparing two means, let’s look at the connection between these two. 

Recall that the values in a confidence interval provide plausible values for the true population parameter. If the null value from hypothesis testing (a two-sided test) does not fall within the confidence interval limits, then this value is not plausible and therefore, we would have evidence that the true population value is different than the null value. That is, the results are statistically significant. This situation is shown in the first plot above: the confidence interval does not include the null value of (in this case) zero. 

Conversely, if the null value falls within the confidence interval limits, then it is a plausible value (one of many different plausible values), and we would not have enough evidence to say the true population value is different than the null value. That is, the results are not statistically significant. This situation is shown in the second plot above: the confidence interval DOES include the null value of zero. 

Reviewing the results from the Tea, Coffee, and the Immune System study, the confidence interval for the difference of means was -1.7 to 35.9. Because 0, the null value, is within that confidence interval, it is a plausible value and we therefore conclude that there is a lack of evidence that the tea and coffee groups have differing mean interferon gamma production. This is the same conclusion that we reached in a previous lecture, when we carried out a hypothesis test for this example and found a p-value of 0.068.

You might be wondering, why use hypothesis testing at all if we could just use a confidence interval to make a conclusion about the population? If we only presented confidence intervals, we would lose information about how incompatible the observed data may be with the null hypothesis. On the other hand, if we only provided p-values, then we would lose information about the magnitude of the difference. Recently, many journals have been modifying their statistical guidelines for authors by requiring them to provide confidence intervals in addition to (or in extreme cases, in place of) p-values. We recommend that you report key study results using a “four-number summary”: the point estimate for the statistic of interest (for example, the difference in means between the treatment and control groups), a confidence interval, and a p-value.We end this lecture with a caution.

In publications, data comparing two or more groups on a continuous outcome are sometimes presented as a bar plot showing the mean for each group (i.e., the height of the bar) and an error bar. The error bars might represent plus or minus the standard deviation for each group, or plus or minus the standard error for each group; or they might represent a confidence interval for the mean for each group. Two of these types of plots from the Tea, Coffee and the Immune System study are presented above, as an example.

It might be tempting to look at whether the error bars overlap in order to make a conclusion about whether the difference in means is statistically significant. But resist the temptation! In reality, you can’t learn much by asking if the two error bars overlap. 

To help you in interpreting these kinds of graphs when reading research articles, a table with the rules of thumb is presented on the slide. Note that these rules only apply when comparing two means and when the sample sizes are equal or nearly equal. 

If the type of error bar is the standard deviation, we can’t actually make any inferential conclusion about whether the group means are significantly different from one another by just looking to see if the error bars overlap. This is because the plot doesn’t display any information about the sample size, which is taken into account when using the t-distribution to compare two means. 

If the type of error bar is the standard error, then we can only conclude the difference is not statistically significant (i.e., the p-value is greater than 0.05) if the two SE error bars overlap. Unfortunately, the opposite does not apply. If two SEM error bars do not overlap, then the p-value could be less than 0.05 or greater than 0.05. We would not know which one it is unless we carried out a hypothesis test or compute a confidence interval for the difference in means. 

Lastly, if the type of error bar is a 95% confidence interval for each group’s mean (plot not displayed on this slide), then we can conclude the difference is statistically significant (i.e., the p-value is less than 0.05) if the two 95% CI error bars do not overlap. The opposite of this is not true. If the two 95% CI error bars do overlap, then the p-value could be less than 0.05 or greater than 0.05. We would not know which it is unless we carried out a hypothesis test or compute a confidence interval for the difference in means.

Rather than memorizing the chart above, we highly recommend that you only make inferences from hypothesis tests or confidence intervals for the actual statistic of interest (in this case, the difference in two group means).